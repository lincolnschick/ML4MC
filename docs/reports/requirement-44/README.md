# Requirement 44

Successful completion of this task includes:
- Training a new model for surviving in a hostile environment: [combat2.pth](https://github.com/lincolnschick/ML4MC/blob/main/docs/reports/requirement-44/combat2.pth)
- Providing the code for training and testing: [fh_combat7.ipynb](https://github.com/lincolnschick/ML4MC/blob/main/docs/reports/requirement-44/fh_combat7.ipynb)
- Videos demonstrating the best modelâ€™s performance: [successful_kill.mp4](https://drive.google.com/drive/folders/1HlwbYbP7knF20CZMNvWT14wGGNyAaVvr?usp=sharing)
- A written report comparing this and the previous model: [README.md](https://github.com/lincolnschick/ML4MC/edit/main/docs/reports/requirement-44/README.md)

The link to drive hosted [successful_kill.mp4](https://drive.google.com/drive/folders/1HlwbYbP7knF20CZMNvWT14wGGNyAaVvr?usp=sharing) contains a video of the successful kill. Video of the training session is 9 minutes and so exceeds the file size limit of GitHub, which is why it is hosted externally. The kill is achieved in the first 15 seconds of the video.

The provided video demonstrates that the new model is capable of defeating enemies under desirable conditions. The video includes a zombie that capable of attacking the agent but has restricted movement because of a partial fence between the zombie and the agent. The agent can be defeated by the zombie if either the agent or the zombie moves around the fence or the agent stays near the fence for an extended period of time, which occurs frequently during training. In the provided video, the agent uses the partial fence to attack the zombie while not approaching close enough to the fence to take lethal damage, and successfully kills the zombie.

The setup was quite tedious, as custom rewards were needed to be implemented, and each iteration of the testing of the reward configuration took an hour. More than 30 combined hours were spend working on this task. It was difficult but rewarding, as the members of this group have greatly learned about the interaction between python and xml. 

The training environment makes a substantial difference in how effectively the agent is able to engage any enemy under limited training iterations. While the agent is not constrained within a limited area of movement, the agent does not attempt to fight and instead learns to stay away from the threat. This is both an easier sequence of inputs to learn and involves less risk of death. When the agent is constrained, it is much more likely to die but sometimes engages with the threat. This is dependent on how the agent is constrained and environmental factors in the area of movement. The agent overall performs poorly in regions only containing a perimeter wall or a hazardous perimeter wall, but performs better with barriers inside the area of movement. A potential cause for this discrepancy is that the fence provides a "safe" region for the agent where it can learn to attack the threat without as much risk of being attacked back. Without the fence, the agent is forced to move away from the threat constantly and face the threat to be able to attack it, which appears through repeated training to be a much more difficult skill to learn.

Therefore, the agent was successful in its mission; there are many more environment configurations to explore in the future, so this may be a step towards the understanding of the immense quantity of combat strategies in Minecraft.
